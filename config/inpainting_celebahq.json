{
    "name": "inpainting_celebahq", // experiments name
    "gpu_ids": [0], // gpu ids list, default is single 0
    "seed" : -1, // random seed, seed <0 represents randomization not used 
    "finetune_norm": false, // find the parameters to optimize

    "path": { //set every part file path
        "base_dir": "experiments", // base path for all log except resume_state
        "code": "code", // code backup
        "tb_logger": "tb_logger", // path of tensorboard logger
        "results": "results",
        "checkpoint": "checkpoint",
        "resume_state": "/kaggle/input/o64-501/501" 
        // "resume_state": null // ex: 100, loading .state  and .pth from given epoch and iteration
    },

    "datasets": { // train or test
        "train": { 
            "which_dataset": {  // import designated dataset using arguments 
                "name": ["data.dataset", "InpaintDataset"], // import Dataset() class / function(not recommend) from data.dataset.py (default is [data.dataset.py])
                "args":{ // arguments to initialize dataset
                    "data_root": "/kaggle/working/huface_origin_64/datasets/celebahq/flist/train_64_28000.flist",
                    "data_len": -1,
                    "mask_config": {
                        "mask_mode": "hybrid",
                        "phase": "train"
                    }
                }
            },
            "dataloader":{
                "validation_split": 4, // percent or number
                "args":{ // arguments to initialize train_dataloader
                    "batch_size": 5, // batch size in each gpu
                    "num_workers": 4,
                    "shuffle": true,
                    "pin_memory": true,
                    "drop_last": true
                },
                "val_args":{ // arguments to initialize valid_dataloader, will overwrite the parameters in train_dataloader
                    "batch_size": 2, // batch size in each gpu
                    "num_workers": 4,
                    "shuffle": false,
                    "pin_memory": true,
                    "drop_last": true
                }
            }
        },
        "test": {
            "which_dataset": {
                "name": "InpaintDataset", // import Dataset() class / function(not recommend) from default file
                "args":{
                    "data_root": "/kaggle/working/huface_origin_64/datasets/celebahq/flist/test_64_2000.flist",
                    "mask_config": {
                        "mask_mode": "center",
                        "phase": "test"
                    }
                }
            },
            "dataloader":{
                "args":{
                    "batch_size": 4,
                    "num_workers": 4,
                    "pin_memory": true
                }
            }
        }
    },

    "model": { // networks/metrics/losses/optimizers/lr_schedulers is a list and model is a dict
        "which_model": { // import designated  model(trainer) using arguments
            "name": ["models.model", "Palette"], // import Model() class / function(not recommend) from models.model.py (default is [models.model.py])
            "args": {
                "sample_num": 8, // process of each image
                "task": "inpainting",
                "ema_scheduler": {
                    "ema_start": 1,
                    "ema_iter": 1,
                    "ema_decay": 0.9999
                },
                "optimizers": [
                    { "lr": 5e-5, "weight_decay": 0}
                ]
            }
        }, 
        "which_networks": [ // import designated list of networks using arguments
            {
                "name": ["models.network", "Network"], // import Network() class / function(not recommend) from default file (default is [models/network.py]) 
                "args": { // arguments to initialize network
                    "init_type": "kaiming", // method can be [normal | xavier| xavier_uniform | kaiming | orthogonal], default is kaiming
                    "module_name": "guided_diffusion", // sr3 | guided_diffusion
                    "unet": {
                        "in_channel": 6,
                        "out_channel": 3,
                        "inner_channel": 64,
                        "channel_mults": [
                            1,
                            2,
                            4,
                            8
                        ],
                        "attn_res": [
                            // 32,
                            16
                            // 8
                        ],
                        "num_head_channels": 32,
                        "res_blocks": 2,
                        "dropout": 0.2,
                        "image_size": 64
                    },
                    "beta_schedule": {
                        "train": {
                            "schedule": "linear",
                            "n_timestep": 2000,
                            // "n_timestep": 10, // debug
                            "linear_start": 1e-6,
                            "linear_end": 0.01
                        },
                        "test": {
                            "schedule": "linear",
                            "n_timestep": 1000,
                            "linear_start": 1e-4,
                            "linear_end": 0.09
                        }
                    }
                }
            }
        ],
        "which_losses": [ // import designated list of losses without arguments
            "mse_loss" // import mse_loss() function/class from default file (default is [models/losses.py]), equivalent to { "name": "mse_loss", "args":{}}
        ],
        "which_metrics": [ // import designated list of metrics without arguments
            "mae" // import mae() function/class from default file (default is [models/metrics.py]), equivalent to { "name": "mae", "args":{}}
        ]
    },

    "train": { // arguments for basic training
        "n_epoch": 546, // max epochs, not limited now
        "n_iter": 1e8, // max interations
        "val_epoch": 1, // valdation every specified number of epochs
        "save_checkpoint_epoch": 10,
        "log_iter": 1e3, // log every specified number of iterations
        "tensorboard" : false,  // tensorboardX enable
        "min_val_mae_loss": 0.03522112965583801,
        "min_val_flag": false,
        "train_previous": [0.14171121259800817, 0.027789672578726807, 0.021782605056307948, 0.019008231214445174, 0.01717432176996337, 0.01705713757985126, 0.01631956299413322, 0.01525886429430704, 0.014911388963170232, 0.015312796009932123, 0.014666173716137564, 0.015023428051796864, 0.014228415989146596, 0.014031730404716882, 0.014156775261692359, 0.013596679461026504, 0.014025686048298895, 0.012988203605891122, 0.01354908014273359, 0.013410291934541714, 0.013390143227129102, 0.013094511619571298, 0.013266082957753049, 0.01378767490228019, 0.013023514449733513, 0.013091798636597988, 0.012520347009517246, 0.013182502645144104, 0.012791115157422444, 0.012310485224638125, 0.0126189018205802, 0.012431390231970759, 0.012637104403562891, 0.012934971962694271, 0.012369826651175581, 0.012427216636002148, 0.011961523567636441, 0.012307649117159255, 0.012684616583881743, 0.01245554559044235, 0.012029736655705786, 0.012718673248145195, 0.012281367397479743, 0.012179195398085756, 0.012047356600321607, 0.012119411223466948, 0.01229985302977656, 0.012401257494348346, 0.012151545002816818, 0.01214480952203966, 0.011658414115874512, 0.011730518156733892, 0.012151588771117931, 0.012156171243556472, 0.011993137221831884, 0.012084316435872844, 0.012399906697366514, 0.01196199795464079, 0.01195070420179781, 0.011904221519124864, 0.011787561456869194, 0.011819349459391547, 0.011594868710168236, 0.011769804247472242, 0.01186894406421027, 0.011771509691152586, 0.01183168673000848, 0.011768121016051881, 0.012284577132969978, 0.011834352081090384, 0.011358533112123308, 0.011649697882548276, 0.011864819155048242, 0.011767525784143012, 0.01133485819474492, 0.011764689030907776, 0.011467596309471039, 0.011541657612369067, 0.011576255267405562, 0.011915649379920703, 0.01129377018286261, 0.011412332242008572, 0.011131772906869461, 0.011633726834847657, 0.011224911291142468, 0.011362639869529428, 0.0112518040676582, 0.011294624949263064, 0.011902085279458303, 0.011612061079349784, 0.011670623031367995, 0.011474494256006678, 0.0114116445854912, 0.01128176809122817, 0.0117656768403455, 0.011137642020299819, 0.011459522520187481, 0.011799764998726706, 0.010990398489446614, 0.011326699157412521, 0.010954232167760996, 0.010937221037766018, 0.01095986681051666, 0.011086713490188438, 0.0110344390384003, 0.010697362379458656, 0.011087672714496816, 0.011497145023595754, 0.011275399971266163, 0.011155475330645856, 0.01132020553029248, 0.011419116065435893, 0.01129828296966807, 0.011290505518817093, 0.01056608651005389, 0.010943340748929492, 0.011280067725250295, 0.010877035972856443, 0.011454823821332815, 0.011064317111858905, 0.010941431840763315, 0.011448721009338967, 0.010812336656552651, 0.011427562269436474, 0.01102140988747911, 0.011424617466897831, 0.011236321784927387, 0.011575541654839358, 0.011402305310053821, 0.011312344884422931, 0.011384055373179913, 0.01099019241918307, 0.011107801243489479, 0.011016574689682881, 0.010810612356481479, 0.01174663474035872, 0.010851115647801444, 0.011337856123824382, 0.011239078791094499, 0.010488261397857771, 0.010988705190382763, 0.010722130120087655, 0.011144396514464324, 0.010798407091927037, 0.010690288716879876, 0.010512306487799787, 0.010520316061796833, 0.01091179149343752, 0.0112592201324795, 0.010908567660476085, 0.01061053702495973, 0.010978781830166356, 0.010753296699716936, 0.010690492476866265, 0.01031256171042812, 0.010707423589314532, 0.010901555644908483, 0.010685948121177954, 0.010854955962580846, 0.01086711205092168, 0.01051026010587904, 0.011117771894433684, 0.010586215494474652, 0.011344277570355037, 0.011257870673236681, 0.010501640550215881, 0.010530510805542582, 0.010606392333213095, 0.010666138816590955, 0.01061390936216356, 0.01063874757034264, 0.010581216980824317, 0.010933417890057058, 0.010630411988316464, 0.011019332086205836, 0.01100767948444741, 0.01048797523205634, 0.010740512496586982, 0.010830256808358625, 0.010620501108287321, 0.010834630618586498, 0.010694813713273419, 0.010800527556494926, 0.010783656951861384, 0.010703193196179236, 0.010813684543174771, 0.010713574289814702, 0.011245911497486296, 0.011004597382025045, 0.010971252190312053, 0.01127796393821432, 0.010425734309040698, 0.010997739209447119, 0.010939088656295675, 0.010577647322070734, 0.010492271504748574, 0.010322723225399316, 0.010689696540218877, 0.010356147248697958, 0.010949629406460024, 0.01080368391701176, 0.010947743347716848, 0.010885605697523087, 0.011201217098109551, 0.010640956026770032, 0.011068040734601471, 0.010286833815268319, 0.010197265248151371, 0.010786265584417452, 0.010958191558612667, 0.01099888230352658, 0.010824869822211185, 0.010572784407707349, 0.010729641488206126, 0.010684506026403612, 0.010642807786209013, 0.010368587001713324, 0.010550394658291766, 0.010563197521972122, 0.010629594790711535, 0.010082612112231795, 0.010766305298926237, 0.01111778615462883, 0.010749798597341596, 0.010723068101352656, 0.010782014632996337, 0.010735500444887688, 0.010427856936034185, 0.010834348373612726, 0.01082131920594434, 0.010248709989160883, 0.010865276958233853, 0.010452664710397946, 0.010296125748789955, 0.010677958961090823, 0.010837491438225672, 0.01098783026833653, 0.010108517439347054, 0.010664022973137602, 0.010248851892616758, 0.010139488613143672, 0.010597743372907902, 0.010917172113950794, 0.010257960410066646, 0.010495832038196108, 0.01073022470717132, 0.010686545019614442, 0.010399178989775179, 0.010260293237184871, 0.010659145443713892, 0.0104389666572165, 0.010557089593715535, 0.010132879418490595, 0.010680086805167799, 0.010475516499868418, 0.009960992370068415, 0.010693398615187371, 0.010182917227297538, 0.010227340535020953, 0.01050723323469179, 0.010449469534173838, 0.010402543046371835, 0.010372737329461946, 0.010692736268461307, 0.010216442862863672, 0.010116935043892446, 0.010374318092467829, 0.010305896660537961, 0.010322399136579128, 0.010431262142370116, 0.01022831524686329, 0.010635370435839205, 0.010833459613342273, 0.010069709524269511, 0.010443504367721882, 0.010329239887706405, 0.011026586890533471, 0.01083031709997922, 0.01031454760062468, 0.009875897791733798, 0.01088147995149833, 0.010052610785805119, 0.010237245813524191, 0.010160141925266802, 0.009844826142764433, 0.009992038105531453, 0.010160586141231498, 0.01054929707943573, 0.010557565529103634, 0.010048810149853645, 0.010267895428193778, 0.010253265610614801, 0.010120976374268082, 0.01014566390745026, 0.010543481884075537, 0.01017340289901614, 0.009883646822097199, 0.010469090189408895, 0.010009962071851718, 0.010811406147348865, 0.010238268014406682, 0.009943285458112067, 0.010109916203983705, 0.010532195341594457, 0.009936167223690761, 0.009863402053637336, 0.010312397405209865, 0.010412520615923003, 0.010375773646985479, 0.010579422862107434, 0.01052347242386004, 0.01007006237802433, 0.010224899801559101, 0.010320434198473194, 0.010015607906901333, 0.010064049564034548, 0.010270894235992787, 0.010382171377508518, 0.01044660095841726, 0.010039204651033409, 0.010402132470212088, 0.010337222682900054, 0.010039335073462217, 0.010125252318720654, 0.010053572355123275, 0.009703375322625513, 0.010807627938528457, 0.010357222645959252, 0.0103535897650392, 0.010424117749668019, 0.010360394158361026, 0.010747015383982952, 0.010441211110019832, 0.010051641829745522, 0.010075519614115422, 0.010212832564805624, 0.010358672737201232, 0.010025011792839565, 0.0101318647360689, 0.01015311252045063, 0.010063858375816104, 0.01017434269605202, 0.009828176941559658, 0.010178957868428894, 0.010314569374051353, 0.010388239881494279, 0.009964670751252944, 0.010176071483641348, 0.01013297736429457, 0.010047155110957658, 0.009954066803725027, 0.009822246041129164, 0.010354426164079663, 0.009944886887743908, 0.010057146546846744, 0.010198919201091687, 0.0098317722507234, 0.010206820834823025, 0.010248575334915366, 0.010318561965609315, 0.010438688395537053, 0.010189706503336214, 0.009622558105685674, 0.01019210924942384, 0.009652101218355025, 0.010180311546681775, 0.009961367354914881, 0.00972771941310633, 0.010149905488261618, 0.010621801033044836, 0.010159876439219397, 0.009721332341146714, 0.010057091830691424, 0.00956013897989102, 0.010283374318058819, 0.009954162712033069, 0.00986633108596843, 0.009883037984415524, 0.009632445564100147, 0.01038326274325199, 0.009532276580737579, 0.010570066030355471, 0.010295564732574296, 0.009712256139323062, 0.010025279889101306, 0.00974858925560667, 0.0100486208829974, 0.01034717995986109, 0.010091444983316385, 0.009698723326898166, 0.01010129604329815, 0.009602012999101529, 0.009891725258162915, 0.009749792957774632, 0.010096751683313332, 0.009747948232852207, 0.009682411708806534, 0.00991824430300211, 0.009960643458715482, 0.009992271824038886, 0.00956465079596251, 0.009869120738403223, 0.010171125795190836, 0.009632549460206715, 0.010011279755051214, 0.009749023033842098, 0.010007003495832835, 0.009925381123639962, 0.01011865530274033, 0.009776352605432505, 0.009961367354914881, 0.00972771941310633, 0.010149905488261618, 0.010621801033044836, 0.010159876439219397, 0.009721332341146714, 0.010057091830691424, 0.00956013897989102, 0.010283374318058819, 0.009954162712033069, 0.00986633108596843, 0.009883037984415524, 0.009632445564100147, 0.01038326274325199, 0.009532276580737579, 0.010570066030355471, 0.010295564732574296, 0.009712256139323062, 0.010025279889101306, 0.00974858925560667, 0.0100486208829974, 0.01034717995986109, 0.010091444983316385, 0.009698723326898166, 0.01010129604329815, 0.009602012999101529, 0.009891725258162915, 0.009749792957774632, 0.010096751683313332, 0.009747948232852207, 0.009682411708806534, 0.00991824430300211, 0.009960643458715482, 0.009992271824038886, 0.00956465079596251, 0.009869120738403223, 0.010171125795190836, 0.009632549460206715, 0.010011279755051214, 0.009749023033842098, 0.010007003495832835, 0.009925381123639962, 0.01011865530274033, 0.009776352605432505, 0.00962700170537195, 0.010118543599529902, 0.009835938932418489, 0.009754565548451399, 0.009818843808273943, 0.009807399159346615, 0.01034155583274216, 0.009700051687858686, 0.010217959285325812, 0.01000873960943385, 0.009946666491347862, 0.010170856482280449, 0.009926107288079484, 0.009912825548304135, 0.009992083064130299, 0.009626852980615401, 0.009871203159138755, 0.009950033595862025, 0.010091591801407061, 0.010223697427786688, 0.010120751904243669, 0.009602054857977478, 0.00978273179306161, 0.009910189979218437, 0.009790317394515555, 0.009922075404867267, 0.009715549972223672, 0.010516402712559323, 0.009756041854513441, 0.009865748577593874, 0.009663005581907021, 0.009721541551385656, 0.009705606750135586, 0.010281602479363284, 0.009614952764257348, 0.009909478519734248, 0.009856802481772575, 0.009843894472511511, 0.009965738934563375, 0.0098880865310415, 0.009940610300725598, 0.00989220143462794, 0.009754628806652265, 0.010102183046890815, 0.009724530595928031, 0.009722823638124184, 0.010031018548675157, 0.009743114556782242, 0.00975420846999864, 0.010068109372335012, 0.00960161921709684, 0.009880979430301053, 0.009694302274574965, 0.009872534860008692, 0.009845769355349067, 0.010212287034704885, 0.009659739683794428, 0.009913090985687224, 0.010082324274169078, 0.009509298939761223, 0.009881676777702755, 0.009948628710072268, 0.009812687868427851, 0.009351556711708531, 0.009696386438693142, 0.010117422600489177, 0.00972436116741412, 0.009868282522781675, 0.009466883988769194, 0.009556055432949467, 0.009922878256322798, 0.009826978536988383, 0.010007083827787514, 0.009819913675999305, 0.009795930466367508, 0.009583355162241678, 0.009586475338089807, 0.009705839111693319, 0.009580968767752327, 0.009881389695310437, 0.009891908581919802, 0.010152819595186054, 0.009477149209953127, 0.009407920925556342, 0.009769962143996523, 0.009852731840089118, 0.00997589427332722, 0.00957420956948276, 0.009539196592311588, 0.009630076595593808, 0.009292440098381812],
        "eval_previous": [0.08896154165267944, 0.09419530630111694, 0.08126145601272583, 0.06088286638259888, 0.08187553286552429, 0.17918282747268677, 0.06116771697998047, 0.07829952239990234, 0.06558066606521606, 0.07000168412923813, 0.10218538343906403, 0.06895051151514053, 0.074799083173275, 0.0661376565694809, 0.06290815770626068, 0.05549833923578262, 0.07926825433969498, 0.048828691244125366, 0.057863205671310425, 0.057143405079841614, 0.05966991186141968, 0.057391561567783356, 0.05024910718202591, 0.07110579311847687, 0.06357263028621674, 0.055347539484500885, 0.051644716411828995, 0.05168180540204048, 0.05733927711844444, 0.05357825383543968, 0.045761577785015106, 0.047207482159137726, 0.05410505831241608, 0.06169970706105232, 0.05429694801568985, 0.04593948274850845, 0.05202121287584305, 0.04920237883925438, 0.04893288016319275, 0.04858493059873581, 0.051036253571510315, 0.05213205888867378, 0.05161762982606888, 0.05895065516233444, 0.05047230049967766, 0.05217670276761055, 0.05220368504524231, 0.051187675446271896, 0.05257386714220047, 0.04787846654653549, 0.03961271792650223, 0.05816147103905678, 0.05209854990243912, 0.04762998968362808, 0.04819308966398239, 0.04771817475557327, 0.05253436416387558, 0.04929102212190628, 0.05324907600879669, 0.0502055399119854, 0.054067373275756836, 0.04114088416099548, 0.04826591908931732, 0.0479629710316658, 0.04833730310201645, 0.06122761219739914, 0.04807593673467636, 0.05451729893684387, 0.04032459855079651, 0.047872886061668396, 0.044995248317718506, 0.04869566857814789, 0.04452921450138092, 0.043485015630722046, 0.049904271960258484, 0.041117049753665924, 0.04111367464065552, 0.04561472684144974, 0.05315365642309189, 0.050785839557647705, 0.052651599049568176, 0.04778595268726349, 0.04489140212535858, 0.047328490763902664, 0.04912508279085159, 0.05351122096180916, 0.03637281805276871, 0.047212496399879456, 0.04932805150747299, 0.05491504445672035, 0.04282993823289871, 0.05971226096153259, 0.04459305852651596, 0.045629631727933884, 0.04256581887602806, 0.04820258915424347, 0.04813282936811447, 0.042610324919223785, 0.05003880709409714, 0.04407951235771179, 0.04750942811369896, 0.045320067554712296, 0.040696680545806885, 0.045076269656419754, 0.04604499787092209, 0.04268178343772888, 0.04353155195713043, 0.04560569301247597, 0.04701612889766693, 0.04986010491847992, 0.042332470417022705, 0.03935414180159569, 0.045993395149707794, 0.051086682826280594, 0.04603815823793411, 0.05249318107962608, 0.04408474266529083, 0.04261007905006409, 0.04537983238697052, 0.04598647356033325, 0.0468723326921463, 0.046217262744903564, 0.044577643275260925, 0.04663648456335068, 0.050431277602910995, 0.047403376549482346, 0.04349733889102936, 0.044720664620399475, 0.04451676458120346, 0.04723319783806801, 0.04157969355583191, 0.050434693694114685, 0.04177762567996979, 0.04575473070144653, 0.043981343507766724, 0.0437651090323925, 0.046817291527986526, 0.04340876266360283, 0.05296029895544052, 0.047352470457553864, 0.04018896073102951, 0.04609721899032593, 0.04242170602083206, 0.049748700112104416, 0.04179946705698967, 0.045706748962402344, 0.04122991859912872, 0.04198087006807327, 0.052952930331230164, 0.04099979251623154, 0.04234663024544716, 0.03985188156366348, 0.038715604692697525, 0.04728791117668152, 0.041747085750103, 0.04779931902885437, 0.046037957072257996, 0.0455712154507637, 0.04505431652069092, 0.04054635763168335, 0.047175198793411255, 0.04347596317529678, 0.04233810678124428, 0.04740580543875694, 0.05034123733639717, 0.04406529292464256, 0.040314432233572006, 0.04915351793169975, 0.040445759892463684, 0.04589773342013359, 0.043541550636291504, 0.036892786622047424, 0.03893355652689934, 0.053451333194971085, 0.04549567401409149, 0.03659503906965256, 0.050924040377140045, 0.04190557077527046, 0.046279989182949066, 0.038649775087833405, 0.04524477198719978, 0.04128468409180641, 0.04226990416646004, 0.04429186135530472, 0.043692827224731445, 0.041242245584726334, 0.043460577726364136, 0.042360953986644745, 0.040447987616062164, 0.04079659283161163, 0.04642295837402344, 0.04165114462375641, 0.04143381863832474, 0.04509872570633888, 0.03782445937395096, 0.039202723652124405, 0.046096235513687134, 0.04174307361245155, 0.044243790209293365, 0.04140513390302658, 0.04081549495458603, 0.041428305208683014, 0.040965963155031204, 0.046912793070077896, 0.04004884883761406, 0.043315038084983826, 0.045848146080970764, 0.04025403782725334, 0.046781644225120544, 0.042532142251729965, 0.04490169882774353, 0.04308521747589111, 0.03975653648376465, 0.041676707565784454, 0.04922632873058319, 0.04458381235599518, 0.047789204865694046, 0.03946547210216522, 0.04545574635267258, 0.04208136349916458, 0.04411336034536362, 0.04408092051744461, 0.045432791113853455, 0.05148695409297943, 0.03995509073138237, 0.04217804968357086, 0.039269112050533295, 0.04049435257911682, 0.048310786485672, 0.041530296206474304, 0.04118015617132187, 0.046675294637680054, 0.044309988617897034, 0.04327966645359993, 0.0460432767868042, 0.04660215228796005, 0.044563136994838715, 0.04425323009490967, 0.041769951581954956, 0.038867801427841187, 0.045769572257995605, 0.0429680310189724, 0.04811543971300125, 0.04760152846574783, 0.043583061546087265, 0.04101439565420151, 0.0440547913312912, 0.03811419755220413, 0.04637840390205383, 0.04558907821774483, 0.03867284208536148, 0.04372512549161911, 0.04401957243680954, 0.04868168756365776, 0.04298334941267967, 0.04128287732601166, 0.04520038515329361, 0.04247283563017845, 0.043707020580768585, 0.03859855979681015, 0.04846159368753433, 0.04199041426181793, 0.04171368479728699, 0.04196006804704666, 0.046787962317466736, 0.04626674950122833, 0.04370211064815521, 0.041655778884887695, 0.0397985577583313, 0.04052708297967911, 0.05021185800433159, 0.04331351816654205, 0.047807443886995316, 0.048869211226701736, 0.037523381412029266, 0.04973951727151871, 0.03878895193338394, 0.04611533135175705, 0.04160439223051071, 0.04721645265817642, 0.041311219334602356, 0.04004734009504318, 0.043123893439769745, 0.04707680642604828, 0.04026040434837341, 0.040858194231987, 0.03784574568271637, 0.04760804772377014, 0.03990576043725014, 0.04477588087320328, 0.04339948296546936, 0.04427766427397728, 0.042006999254226685, 0.04384122043848038, 0.04171963781118393, 0.042432751506567, 0.04310578107833862, 0.040957603603601456, 0.041213586926460266, 0.04094601795077324, 0.04079898074269295, 0.040341489017009735, 0.04468052461743355, 0.03996897116303444, 0.04408358782529831, 0.039546899497509, 0.04735191911458969, 0.0378655381500721, 0.04445343837141991, 0.04479553550481796, 0.044837310910224915, 0.042007993906736374, 0.04145762324333191, 0.04588852822780609, 0.04320521652698517, 0.046517513692379, 0.04170721024274826, 0.042305782437324524, 0.04072750359773636, 0.045249395072460175, 0.04168889299035072, 0.04393570125102997, 0.03933124244213104, 0.042025066912174225, 0.04137716442346573, 0.04297346621751785, 0.03522112965583801, 0.03974631428718567, 0.047811977565288544, 0.04497414454817772, 0.04334934055805206, 0.04068189486861229, 0.037646353244781494, 0.04402831941843033, 0.04159616678953171, 0.04431915283203125, 0.03841089829802513, 0.04533439874649048, 0.04132821783423424, 0.043748192489147186, 0.03961716592311859, 0.048440270125865936, 0.03674895316362381, 0.044934771955013275, 0.040363796055316925, 0.043344102799892426, 0.03894805908203125, 0.04501470550894737, 0.04612291604280472, 0.040738631039857864, 0.04102522134780884, 0.03876395896077156, 0.0433645099401474, 0.04206056147813797, 0.04008618742227554, 0.044168371707201004, 0.04486142098903656, 0.04332819581031799, 0.042023491114377975, 0.04211512953042984, 0.04309435188770294, 0.04143817722797394, 0.04635390639305115, 0.04438290745019913, 0.04432597756385803, 0.04143820330500603, 0.04607181251049042, 0.042351096868515015, 0.04289659112691879, 0.0438566580414772, 0.042582131922245026, 0.04281741753220558, 0.039432309567928314, 0.047316424548625946, 0.04331536591053009, 0.043152663856744766, 0.04745914414525032, 0.04421938955783844, 0.04126517474651337, 0.042535435408353806, 0.04126565158367157, 0.04928559809923172, 0.043636370450258255, 0.041049160063266754, 0.036461200565099716, 0.046143367886543274, 0.04416626691818237, 0.04326567053794861, 0.04135521501302719, 0.0413786917924881, 0.04193802550435066, 0.044786036014556885, 0.04263211414217949, 0.0433034673333168, 0.044838398694992065, 0.041743189096450806, 0.042277127504348755, 0.049525097012519836, 0.04081983119249344, 0.04364992678165436, 0.04485837370157242, 0.049800291657447815, 0.04173470288515091, 0.045778654515743256, 0.04161354899406433, 0.036085814237594604, 0.04111621901392937, 0.04653342440724373, 0.05151374638080597, 0.043266765773296356, 0.04607181251049042, 0.042351096868515015, 0.04289659112691879, 0.0438566580414772, 0.042582131922245026, 0.04281741753220558, 0.039432309567928314, 0.047316424548625946, 0.04331536591053009, 0.043152663856744766, 0.04745914414525032, 0.04421938955783844, 0.04126517474651337, 0.042535435408353806, 0.04126565158367157, 0.04928559809923172, 0.043636370450258255, 0.041049160063266754, 0.036461200565099716, 0.046143367886543274, 0.04416626691818237, 0.04326567053794861, 0.04135521501302719, 0.0413786917924881, 0.04193802550435066, 0.044786036014556885, 0.04263211414217949, 0.0433034673333168, 0.044838398694992065, 0.041743189096450806, 0.042277127504348755, 0.049525097012519836, 0.04081983119249344, 0.04364992678165436, 0.04485837370157242, 0.049800291657447815, 0.04173470288515091, 0.045778654515743256, 0.04161354899406433, 0.036085814237594604, 0.04111621901392937, 0.04653342440724373, 0.05151374638080597, 0.043266765773296356, 0.04542155563831329, 0.03968685120344162, 0.039993248879909515, 0.0428222119808197, 0.04190050810575485, 0.044997528195381165, 0.04143673926591873, 0.04385169595479965, 0.04481034725904465, 0.04001390188932419, 0.04442819207906723, 0.040900737047195435, 0.038153134286403656, 0.039786383509635925, 0.045845381915569305, 0.0481213703751564, 0.04087132215499878, 0.03962761536240578, 0.0400528684258461, 0.04400871694087982, 0.04472611844539642, 0.0431203693151474, 0.041729193180799484, 0.0418446883559227, 0.04127573221921921, 0.048484861850738525, 0.04165322706103325, 0.04256309196352959, 0.046847157180309296, 0.04102860391139984, 0.04106497764587402, 0.036988649517297745, 0.03840980306267738, 0.045426156371831894, 0.0400928296148777, 0.03802008926868439, 0.04479832947254181, 0.043676409870386124, 0.043040838092565536, 0.046517401933670044, 0.043375805020332336, 0.04615670442581177, 0.04380634427070618, 0.04484272375702858, 0.03642915189266205, 0.04621061682701111, 0.04383215308189392, 0.04270517826080322, 0.04238944500684738, 0.039927296340465546, 0.039899230003356934, 0.044689081609249115, 0.0427573099732399, 0.04498061165213585, 0.04906667396426201, 0.03913447633385658, 0.04217371344566345, 0.0409555584192276, 0.03912818059325218, 0.03871910274028778, 0.03893482685089111, 0.04304009675979614, 0.040337227284908295, 0.03841524198651314, 0.04063261300325394, 0.04263041168451309, 0.04160812497138977, 0.03959496319293976, 0.03911662846803665, 0.04616136848926544, 0.042769938707351685, 0.04102978855371475, 0.03741976618766785, 0.04329978674650192, 0.04241577908396721, 0.03962139040231705, 0.04282013699412346, 0.045094043016433716, 0.043225958943367004, 0.03962021693587303, 0.04035438224673271, 0.03956343233585358, 0.042908474802970886, 0.04170536994934082, 0.04320545494556427, 0.042663685977458954, 0.04333459585905075, 0.04753950238227844, 0.03650389239192009, 0.04451682046055794, 0.0476563461124897]
    },

    "debug": { // arguments in debug mode, which will replace arguments in train
        "val_epoch": 1,
        "save_checkpoint_epoch": 1,
        "log_iter": 2,
        "debug_split": 50 // percent or number, change the size of dataloder to debug_split.
    }
}
